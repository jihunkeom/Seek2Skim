# Seek2Skim
Dynamic Layer-wise Token Pruning for Sequence-to-Sequence Transformer Inference


If you find this repo useful for your research, please consider citing our paper:
```
@inproceedings{keom2024dynamic,
  title={Dynamic Layer-Wise Token Pruning for Sequence-to-Sequence Transformer Inference},
  author={Keom, Ji Hun and Kim, Yeachan and Lee, Sung Ju and Lee, Sang Keun},
  booktitle={International Conference on Pattern Recognition and Artificial Intelligence},
  pages={339--353},
  year={2024},
  organization={Springer}
}
```
